---
title: "STAT 331 Portfolio"
author: "Adam Kong"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv}
# Week 7: Lab 7 Q 0

fish <- read_csv(here::here("Week 7", 
                            "Lab 7", 
                            "BlackfootFish.csv"))
```

-   `xlsx`

```{r wd-1-xlsx}
# Week 2: Practice Activity Data Import Q 1

read_xlsx(here::here("Week 2", 
                     "Practice Activity", 
                     "Ages_Data", 
                     "ages.xlsx"))
```

-   `txt`

```{r wd-1-txt}
# Week 5: Practice Activity 5.1 regex Setup

message <- read_tsv(here::here("Week 5",
                               "Practice Activity 5",
                               "data", 
                               "scrambled_message.txt"))
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2}
# Week 3: Lab 3 Q 9

hiphop_clean |>
  select(subj, sex, age, ethnic) |>
  distinct(subj, .keep_all = TRUE) |>
  summary()
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
# Week 3: Lab 3 Q 11

hiphop_clean |>
  filter(age < 20) |>
  group_by(word) |>
  summarize(mean_words = mean(familiarity)) |>
  slice_max(mean_words)
```

-   character -- specifically a string

```{r wd-3-string}
# Week 5: Practice Activity 5.1 Q 3

message |>
  filter(str_detect(Word, pattern = "^m"))
```

-   factor

```{r wd-3-factor}
# Week 3: Lab 3 Q 13

hiphop_clean |>
  filter(sex == 'Male', ethnic == 'white', age > 30) |>
  group_by(word) |>
  summarize(mean_words3 = mean(familiarity)) |>
  slice_max(mean_words3)
```

-   date

```{r wd-3-date}
# Week 5: Practice Activity 5.2 Lubridate Q 1

suspects_clean <- suspects |>
  filter(pm(Time.Spotted))
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
# Week 7: Challenge 7 Q 4.1

fish <- fish |>
  mutate(weight = weight *28.35)
```

-   character -- specifically a string

```{r wd-4-string}
# Week 5: Practice Activity 5.1 Regex Q 6

message |>
  mutate(word_count = str_length(Word)) |>
  slice_max(word_count)
```

-   factor

```{r wd-4-factor}
# Week 4: Lab 4 Q 7 (Revised)

recreate_graph <- cali_avocados |>
  pivot_longer(cols = Small:ExtraLarge,
               names_to = "Avocado Size",
               values_to = "Avocado_Sold") |>
  group_by(region, type, `Avocado Size`) |>
  summarise(mean_sold = mean(Avocado_Sold)) |>
  mutate(`Avocado Size`= factor(`Avocado Size`, level = c('Small',
                                                          'Large',
                                                          'ExtraLarge')))
```

-   date

```{r wd-4-date}
# Week 5 Practice Activity 5.1 Setup

suspects_clean <- suspects |>
  mutate(Time.Spotted = ymd_hms(Time.Spotted))
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}
# Week 4: Challenge 4 (Revised)

# NOTE: I revised this because left_join was not the correct join for the challenge. However I revised the solution to use inner_join. But I did not use left_join anywhere else in the quarter.


combined_data <- cali_avocados |>
  left_join(HPI_index, by = "region") |>
  filter(year.x == year.y) |>
  group_by(year.x, region, AveragePrice)

```

-   `right_join()`

```{r wd-5-right}
# Week 4: Lab 4 Q 5

# NOTE: I would use a semi_join here after the resubmissions. But because I did not use a resubmissions for a correct solution for this learning target I can't use a right_join I have in the corrected challenge 4. I could just reverese the order of the combined_data set to be the right join instead by flipping cali_avocados and HPI_index.

graphFiveMetro <- avocado |>
  right_join(topFiveRegions)
```

-   `inner_join()`

```{r wd-5-inner}
# Week 4: Challenge 4

combined_data <- cali_avocados |>
  inner_join(HPI_index, by = c("year", "region")) |>
  group_by(year, region) |>
  select(year, region, AveragePrice, index_nsa) |>
  summarise(year_nsa = mean(index_nsa), 
            AveragePrice = mean(AveragePrice))
```

-   `full_join()`

```{r wd-5-full}
# Week 4: Practice Activity 11 Q 1 (Quiz on Canvas Screenshot include in support)

prof |>
  full_join(prof_info, prof_course)
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
# Week 4: Lab 4 Q 2

region_major <- tibble(region = c("GreatLakes",
                                  "Midsouth",
                                  "Northeast",
                                  "Plains",
                                  "SouthCentral",
                                  "Southeast",
                                  "West")
                       )

region_avocado <- avocado |>
  semi_join(region_major, by = "region")
```

-   `anti_join()`

```{r wd-6-anti}
# Week 4: Lab 4 Q 2

region_major <- tibble(region = c("GreatLakes",
                                  "Midsouth",
                                  "Northeast",
                                  "Plains",
                                  "SouthCentral",
                                  "Southeast",
                                  "West")
                       )

region_not_included <- region_major |>
  bind_rows(tibble(region = c("California",
                              "SouthCarolina",
                              "TotalUS")))

metro_avocado <- avocado |>
  anti_join(region_not_included)
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r wd-7-long}
# Week 4: Lab 4 Q 7 (Revised)

recreate_graph <- cali_avocados |>
  pivot_longer(cols = Small:ExtraLarge,
               names_to = "Avocado Size",
               values_to = "Avocado_Sold") |>
  group_by(region, type, `Avocado Size`) |>
  summarise(mean_sold = mean(Avocado_Sold)) |>
  mutate(`Avocado Size`= factor(`Avocado Size`, level = c('Small',
                                                          'Large',
                                                          'ExtraLarge')))
```

-   `pivot_wider()`

```{r wd-7-wide}
# Week 4: Lab 4 Q 6

cali_organic_convention <- cali_avocados |>
  group_by(type, region) |>
  summarise(meanprice = mean(AveragePrice)) |>
  pivot_wider(names_from = type, 
               values_from = meanprice) |>
  mutate(avocadoDiff = organic - conventional) |>
  select(region, avocadoDiff)
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments: Lab 2 Challenge 2 Lab 3 Challenge 3 Lab 4 (Maybe).

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1}
# Week 3: Lab 3 Q 4

hiphop |>
  select(c(asianMove:blackWeekly)) |>
  summarise(across(everything(), mean))
```

-   Example 2

```{r r-2-2}
# Week 4: Lab 4 Q 7 (Revised)

recreate_graph <- cali_avocados |>
  pivot_longer(cols = Small:ExtraLarge,
               names_to = "Avocado Size",
               values_to = "Avocado_Sold") |>
  group_by(region, type, `Avocado Size`) |>
  summarise(mean_sold = mean(Avocado_Sold)) |>
  mutate(`Avocado Size`= factor(`Avocado Size`, level = c('Small',
                                                          'Large',
                                                          'ExtraLarge')))

# https://www.guru99.com/r-factor-categorical-continuous.html#:~:text=What%20is%20Factor%20in%20R,integer%20data%20values%20as%20levels.

ggplot(recreate_graph, aes(fill = `Avocado Size`, 
                           x = region,
                           y = mean_sold)) +
  geom_bar(position = "fill", stat = "identity") +
  facet_wrap(~type) +
  labs(
    x = "Region of CA",
    y = "Proportion of Mean Avocados Sold",
  ) +
  scale_fill_manual(labels = c("Small", "Large", "Extra Large"), values = c("#a6cee3", "#1f78b4", "#b2df8a")) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
  
# https://ggplot2.tidyverse.org/articles/faq-axes.html
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}
# Week 3: Lab 3 Q 14

hiphop_clean |>
  filter(sex == 'Male', ethnic == 'white',
           age > 17, age < 23,
           city > 10000, city < 60000) |>
  slice_max(bieber) |>
  distinct(subj, .keep_all = TRUE)
```

-   Example 2

```{r r-3-2}
# Week 7: Lab 7 Q 3

rescale_01 <- function(vector) {
  
  stopifnot(is.numeric(vector), length(vector) > 1)
  
  min_num <- min(vector, na.rm = TRUE)
  max_num <- max(vector, na.rm = TRUE)
  
  vector = (vector - min_num) / (max_num - min_num)
  
  return(vector)
         
}
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
# Week 2: Lab 2 Q 14

ggplot(data = surveys, aes(x = species, y = weight)) +
  geom_jitter(color = "darkseagreen") +
  geom_boxplot(outlier.shape = NA) + 
  labs(
    title = "Weight Distribution in Grams by Species",
    x = "Species"
  ) +
  theme(
    axis.title.y = element_blank(),
    axis.text.x = element_text(angle=45)
  )

```

-   numeric variables and categorical variables

```{r dvs-2-num-cat}
# Week 4: Lab 4 Q 5 (Revised)

# Top most sold avocados for the five metro regions were:
# Los Angeles, New York, Dallas Fortworth, Houston, Phoenix Tuscon

ggplot(graphFiveMetro, aes(x = region, y = `Total Volume`, fill = region)) +
  geom_boxplot() +
  geom_jitter() +
  labs(
    title = "Highest Average Avocados Sold",
    x = "Region",
    y = "Average Avocado Sold"
  )
```

-   categorical variables

```{r dvs-2-cat}
# Week 5: Lab 5 Part 2 Q 3 (Revised)

ggplot(data = mean_surveys, 
       mapping = aes(x = year, 
                     y = mean_weight, 
                     color = fct_reorder2(genus, 
                                          .x = year, 
                                          .y = mean_weight,
                                          .desc = TRUE))) +
  geom_point(alpha = 0.2) +
  geom_line() +
  labs(
    x = "Year",
    y = "Mean Rodent Weight (g)",
    color = "Rodent Genus"
  )
```

-   dates

```{r dvs-2-date}
# Week 5: Lab 5 Part 3 Q 3

ggplot(data = drop_na(dates_collapsed), 
       mapping = aes(x = level, 
                     y = n, 
                     fill = level )) +
  geom_col() +
  labs(
    title = "Number of Rodents caught during the Week",
    fill = "Week Level"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
# Week 2: Lab 2 Q 14

# Code for question 13! 
ggplot(data = surveys, 
       aes(x = weight, 
           y = species)) +
  geom_jitter(color = "cadetblue", 
              alpha = 0.2) +
  geom_boxplot(outlier.shape = NA) + 
  labs(
    title = "Weight Distribution by Species",
    x = "Weight (g)") +
  theme(
    axis.title.y = element_blank()
    )

# https://www.datanovia.com/en/blog/ggplot-axis-labels/
```

-   Example 2

```{r dvs-2-2}
# Week 5: Lab 5 Part 2 Q 3 (Revised)

ggplot(data = mean_surveys, 
       mapping = aes(x = year, 
                     y = mean_weight, 
                     color = fct_reorder2(genus, 
                                          .x = year, 
                                          .y = mean_weight,
                                          .desc = TRUE))) +
  geom_jitter(alpha = 0.2) +
  geom_line() +
  labs(
    x = "Year",
    y = "Mean Rodent Weight (g)",
    color = "Rodent Genus"
  )
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}
# Week 2: Ugly Penguin Competition


ugly <- ggplot(data = penguins) + 
  geom_point(mapping = aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = island, size = year, alpha = body_mass_g)) +
  labs(x = "BiLL lenGtH(mM0)", y = "bIlL leNgTh9(mm))") + 
  scale_shape_manual(values = c(9, 16, 19)) + 
  theme_light() +
  geom_smooth(mapping = aes(x = bill_length_mm, y = bill_depth_mm, color = island))

ugly + theme(
  panel.background = element_rect(fill = "#7B3F00", size = 5)) +
  theme(plot.background = element_rect(fill = "#FFFF00", size = 0.1))
```

-   Example 2

```{r dvs-3-2}
# Week 7: Challenge 7 Q 3

ggplot(data = fish_clean) +
  facet_wrap(~species) +
  geom_jitter(mapping = aes(x = year, 
                            y = cond_index, 
                            color = section),
              alpha = 0.25) +
  labs(
    title = "Conditional Index of Fish Distribution",
    x = "Year",
    y = "",
    color = "Section"
  )
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
# Week 3: Lab 3 Q 4

hiphop |>
  select(c(asianMove:blackWeekly)) |>
  summarise(across(everything(), mean))
```

-   Example 2

```{r dvs-4-2}
# Week 5: Lab 5 Q 2

mean_surveys <- surveys |>
  group_by(year, genus) |>
  summarise(mean_weight = mean(weight))
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
# Week 5: Lab 5 Q 2

mean_surveys <- surveys |>
  group_by(year, genus) |>
  summarise(mean_weight = mean(weight))
```

-   Example 2

```{r dvs-5-2}
# Week 9: Lab 9 Q 1 (Revised)

tables_sorted <- names |>
  filter(Name == "Allison") |>
  rename(Sex = Gender) |>
  pivot_wider(names_from = c(Sex),
              values_from = Count,
              values_fill = 0) |>
  group_by(State) |>
  summarise(F = sum(F), M = sum(M))

tables_sorted
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}
# Week 9: Lab 9 Q 1 (Revised)

tables_sorted <- names |>
  filter(Name == "Allison") |>
  rename(Sex = Gender) |>
  pivot_wider(names_from = c(Sex),
              values_from = Count,
              values_fill = 0) |>
  group_by(State) |>
  summarise(F = sum(F), M = sum(M))

tables_sorted
```

-   Example 2

```{r dvs-6-2}
# Week 4: Lab 4 Q 3

region_avocado |>
  filter(year == 2017, type == "organic") |>
  group_by(region) |>
  summarise(small_sum_sold = sum(Small)) |>
  slice_max(small_sum_sold)

```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1}
# Week 9: Challenge 9

Allan_PA %>%
  gt() %>%
  cols_label(sum_Alan = "Alan",
             sum_Allan = "Allan",
             sum_Allen = "Allen") %>%
  tab_header(title = "Proportion of 'Allan'",
             subtitle = "from the State of Pennsylvania") %>% 
  fmt_number(columns = 1:3, decimals = 3)
```

-   Example 2

```{r dvs-7-2}
# Week 9: Challenge 9

preview_names <- names |>
  head(100)
DT::datatable(preview_names)
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
# Week 3: Lab 3 Q 14

hiphop_clean |>
  filter(sex == 'Male', ethnic == 'white',
           age > 17, age < 23,
           city > 10000, city < 60000) |>
  slice_max(bieber) |>
  distinct(subj, .keep_all = TRUE)
```

-   `across()`

```{r pe-1-across}
# Week 4: Practice Activity 4: Military Q 2

military_clean <- military |>
  mutate(across(.cols = Country:`2019`, .fns = ~na_if(., "xxx")),
         across(.cols = Country:`2019`, .fns = ~na_if(., ". .")))
```

-   `map()` functions

```{r pe-1-map-1}
# Week 8: Lab 8 Q 4

xmas3 <- xmas2 %>%
mutate(full_line = map_chr(.x = Day, 
                           ~sing_day(xmas2, 
                                     .x, 
                                     Full.Phrase)))
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}
# Week 8: Lab 8 Q 3

sing_day <- function(dataset, line, phrase_col){
  
  # Step 1: Setup the intro line
  # Hint: You need to convert a number (e.g., 1) to a word (e.g., first)
  num_word <- ordinal({{ line }})
  
  intro <- glue::glue("On the {num_word} day of Christmas, my true love sent to me:")
  
  # Step 2: Sing the gift phrases

  phrases <- dataset |>
    pull( {{phrase_col}} )
  
  if ({{ line }} == 1) {
  combined_phrase <- str_flatten(phrases[{{ line }}:1], " ")
  } else {
  combined_phrase <- str_c(str_flatten(phrases[{{ line }}:2], " "), 
                           "and",
                           str_flatten(phrases[1], ""), 
                           sep = " ")
  }
    
  ## put it together
  
  final_line2 <- str_c(intro, 
                      combined_phrase,
                      sep = " ")
  final_line <- str_c(final_line2, ".", sep = "")
    
  return(final_line)

}
```

-   Example 2

```{r pe2-2}
# Week 7: Lab 7 Q 3

rescale_01 <- function(vector) {
  
  stopifnot(is.numeric(vector), length(vector) > 1)
  
  min_num <- min(vector, na.rm = TRUE)
  max_num <- max(vector, na.rm = TRUE)
  
  vector = (vector - min_num) / (max_num - min_num)
  
  return(vector)
         
}
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}
# Week 7: Lab 7 Q 3.5

rescale_column <- function(dataframe, variables) {
  
  stopifnot(is.data.frame(dataframe))

  dataframe <- dataframe |>
    mutate(across(.cols = {{ variables }}, 
                  .fns = ~rescale_01(.x),
                  .names = NULL))
  
  return(dataframe)
}
```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}
# Week 8: Lab 8 Q 4

xmas3 <- xmas2 %>%
mutate(full_line = map_chr(.x = Day, 
                           ~sing_day(xmas2, 
                                     .x, 
                                     Full.Phrase)))

```

```{r pe-3-map-2}
# Week 8: Lab 8 Q 1

purrr::map_chr(xmas$Gift.Item, pluralize_gift)
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1

```{r pe-4-1}
# Week 5: Lab 5 Part 3 Q 3

ggplot(data = drop_na(dates_collapsed2), 
       mapping = aes(x = level, 
                     y = n, 
                     fill = level )) +
  geom_col() +
  labs(
    title = "Number of Rodents caught during the Week",
    fill = "Week Level"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )
```

-   Example 2

```{r pe-4-2}
# Week 7: Lab 7 Q 2.1

fish |>
  summarise(across(.cols = everything(vars = NULL), .fns = ~sum(is.na(.x))))
```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}
# Week 9: Practice Activity 9.2 

set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = 0.8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(sum(trombones, cornets, reeds))
  
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, 
                                       n_cor = 110, 
                                       n_reed = 542 + 318 + 175)
                      ) 
```

-   Example 2

```{r dsm-1-2}
# Week 9: Practice Activity 9.2

# Trumpet
qunif(0.95, min = 1.5, max = 3.5)
# Trombone
qnorm(0.10, mean = 4.6, sd = 0.8)
1 - pnorm(5, mean = 4.6, sd = 0.8)
tromboneNum <- rnorm(100, mean = 4.6, sd = 0.8)

sum(tromboneNum < 4)

# Reed
1 - pchisq(5, df = 4)
```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1

```{r dsm-2-1}
# Week 9: Lab 9 Q 4

names_linear <- lm(TotalCount ~ Year, data=Allison_years)
```

-   Example 2

```{r dsm-2-2}
# Week 9: Practice Activity 9.1 Regression

mystery_lm <- lm(weight_after ~ weight_before, data=mystery_animal)
```

## Revising My Thinking

I think a lot of my thinking in code has changed a lot throughout the course. I used to think that long and code meant the code was much better. But after revising my code many times I realized that shorter code is much better. My work and my revisions can be also seen in the challenges. Often times during the challenges I attempt to go beyond the expectations of this class by including additional information and including materials not taught in the regular courses into my assignments. But I've learned that perfection doesn't happen first try. I learnt after having to complete several revisions that striving to perfection is learning. I consider alot of what Professor Theobold and my peer reviews comment on my labs and assignments and try to fit those into my re submissions. A lot of the revision in the portfolio have come from redoing certain problems and understood what the comments meant for each one. Although maybe not all the code is perfect or even correct, I put in effort to try and revise my thinking in order to become a better programmer.

## Extending My Thinking

Throughout the course I take time trying to understand each concept. I dedicate a lot of time to understand concepts and try to use these concepts in the labs afterward. For new materials I first try to figure out new concepts and think of new ways of how I can implement these ideas into an assignment. Then if I can't understand a concept or idea, I'd try to reach out to professor Theobold or use the class Discord to ask questions about a part I don't understand. But most of my time on Discord I found that my other peers have already asked the same questions and I use those answer in my assignments. In my previous reflection, I even mentioned how I extended my thinking beyond the class by including an example from Challenge 1 where I added many more colors and changed the background. In addition I would like to add the ugly plot competition, since that was not part of the normal course but I showed my attempt at extended thinking.

Additionally, while reading the Stat 331 Portfolio Guide I realize that just saying that I put time into this class doesn't justify the high grade I am asking for. I believe that my efficient revised code would be enough or a complete would be enough. **I am putting in effort to get the results to reflect my grade**. I hope that my results do reflect my hard work but I don't expect my hard work to justify my grade without an obvious result first.

## Peer Support & Collaboration

![Answer to a Discord Question](images/Screenshot%202023-02-19%20090445-01.png)

This paragraph was copied and pasted from another one of my reflections. However, I feel as if this does still reflect on how I did regarding peer support and collaboration.

In the two practice activities, I took the roles of facilitator and recorder. During each practice activity I would make sure to engage with my peers and ensure that our group would discuss each problem. When I was the role of recorder I made sure to listen to each suggestion my peers made and made that edit. I noticed while working on the practice activity, when one member would want to correct another team member, that team member would wait for the other team member to finish talking before suggesting the correct solution.

In the Discord I would sometimes ask questions, but I would also look on the Discord for help. So far I have only asked one question so far, but I like Discord because I can look at what other people asked and use those to answer some of the questions I had. I also participate in the Discord chat and try to answer questions whenever I know the answers. To go further I would test their solution, if they posted their code, and confirm whether it would be an issue on my end or their end.
